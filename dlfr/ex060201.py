##### 6.2 ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ

#### 6.2.1 Kerasä¸­çš„å¾ªç¯å±‚

from keras.layers import SimpleRNN

## SimpleRNNå±‚ä¸å…¶å®ƒKeraså±‚ä¸€æ ·å¯ä»¥å¤„ç†åºåˆ—æ‰¹é‡
## å®ƒæ¥æ”¶å½¢çŠ¶ä¸º(batch_size, timesteps, input_features)çš„è¾“å…¥ï¼Œè€Œä¸æ˜¯(timesteps, input_features)

## ä¸€ä¸ªä½¿ç”¨SimpleRNNçš„ä¾‹å­ï¼šåªè¿”å›æœ€åä¸€ä¸ªtimestepçš„è¾“å‡º

from keras.models import Sequential
from keras.layers import Embedding, SimpleRNN
model = Sequential()
# Embeddingå±‚æ˜¯å¹²å˜›çš„æ¥ç€ï¼Ÿ
    # æè¯åµŒå…¥çš„ã€‚
        # ğŸš§ç»™æ­¤å±‚è¾“å…¥ä»€ä¹ˆï¼Ÿ
        # ğŸš§æ­¤å±‚ä¼šè¾“å‡ºä»€ä¹ˆï¼Ÿ
model.add(Embedding(10000, 32))
## è‹¥åœ¨32åé¢å¤šåŠ ä¸€ä¸ªreturn_sequences=Trueï¼Œåˆ™ä½¿æ­¤ä¾‹è¿”å›å®Œæ•´çš„çŠ¶æ€åºåˆ—ï¼ˆçŠ¶æ€åºåˆ—æ˜¯ä»€ä¹ˆæ„æ€â“å“¦ï¼Œä¸€ä¸ªä¸ªçŠ¶æ€å½¢æˆçš„åºåˆ—ã€‚ï¼‰
model.add(SimpleRNN(32))
model.summary()

## ä¸ºäº†æé«˜ç½‘ç»œçš„è¡¨ç¤ºèƒ½åŠ›ï¼Œå°†å¤šä¸ªå¾ªç¯å±‚é€ä¸ªå †å æœ‰æ—¶ä¹Ÿæ˜¯å¾ˆæœ‰ç”¨çš„ã€‚æ­¤æ—¶éœ€è¦è®©æ‰€æœ‰ä¸­é—´å±‚éƒ½è¿”å›å®Œæ•´çš„è¾“å‡ºåºåˆ—ã€‚
model = Sequential()
model.add(Embedding(10000, 32))
model.add(SimpleRNN(32, return_sequences=True))
model.add(SimpleRNN(32, return_sequences=True))
model.add(SimpleRNN(32, return_sequences=True))
## æœ€åä¸€å±‚ä»…è¿”å›æœ€ç»ˆè¾“å‡º
model.add(SimpleRNN(32))
model.summary()


## æ¥ä¸‹æ¥ï¼Œå°†æ­¤æ¨¡å‹åº”ç”¨äºIMDBç”µå½±è¯„è®ºåˆ†ç±»é—®é¢˜

## é¦–å…ˆï¼Œå¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†
### 6-22 å‡†å¤‡IMDBæ•°æ®
from keras.datasets import imdb
from keras.preprocessing import sequence

## ä½œä¸ºç‰¹å¾çš„å•è¯ä¸ªæ•°
max_features = 10000
## åœ¨è¿™ä¹ˆå¤šå•è¯ä¹‹åæˆªæ–­æ–‡æœ¬ï¼ˆè¿™äº›å•è¯éƒ½å±äºå‰max_featuresä¸ªæœ€å¸¸è§çš„å•è¯ï¼‰
maxlen = 500
batch_size = 32

print('Loading data...')
(input_train, y_train), (input_test, y_test) = imdb.load_data(
    # https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification
    num_words=max_features)
print(len(input_train), 'train sequences')
print(len(input_test), 'test sequences')

print('Pad sequences (samples x time)')
input_train = sequence.pad_sequences(input_train, maxlen=maxlen)
input_test = sequence.pad_sequences(input_test, maxlen=maxlen)
print('input_train shape:', input_train.shape)
print('input_test shape:', input_test.shape)


### 6-23 ç”¨ Embedding å±‚å’Œ SimpleRNN å±‚æ¥è®­ç»ƒæ¨¡å‹

from keras.layers import Dense

model = Sequential()
model.add(Embedding(max_features, 32))
model.add(SimpleRNN(32))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
history = model.fit(input_train, y_train,
                    epochs=10,
                    batch_size=128,
                    validation_split=0.2)


### 6-24 ç»˜åˆ¶ç»“æœ

import matplotlib.pyplot as plt

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)

# 'bo': è“è‰²åœ†ç‚¹
# [matplotlib.pyplot.plot â€” Matplotlib 3.2.1 documentation](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html?highlight=plot#matplotlib.pyplot.plot)
plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
# [matplotlib.pyplot.legend â€” Matplotlib 3.2.1 documentation](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.legend.html?highlight=pyplot%20legend#matplotlib.pyplot.legend)
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()