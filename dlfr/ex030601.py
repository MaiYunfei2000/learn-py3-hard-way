##### 3.6 é¢„æµ‹æˆ¿ä»·ï¼šå›å½’é—®é¢˜

#### 3.6.1 æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®é›†

from keras.datasets import boston_housing

(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()

"""
>>> train_data.shape
(404, 13)
>>> test_data.shape
(102, 13)
>>> train_targets
array([15.2, 42.3, 50., ..., 29.1])
"""
## æ¯ä¸ªæ ·æœ¬æœ‰13ä¸ªæ•°å€¼ç‰¹å¾ï¼Œå¦‚äººå‡çŠ¯ç½ªç‡ã€æ¯ä¸ªä½å®…çš„å¹³å‡æˆ¿é—´æ•°ã€é«˜é€Ÿå…¬è·¯å¯è¾¾æ€§ç­‰



#### 3.6.2 å‡†å¤‡æ•°æ®

### 3-25 æ•°æ®æ ‡å‡†åŒ–

# æ ‡å‡†åŒ–è®­ç»ƒæ•°æ®ï¼š
# å°±æ˜¯ç»Ÿè®¡ä¸Šçš„æ ‡å‡†åŒ–ï¼Œå¯¹xè¿›è¡Œ(x - x_bar) / stdå¾—åˆ°æ ‡å‡†åˆ†æ•°z
# æ²¿ç€train_dataçš„ç¬¬0è½´ï¼ˆä¸€åˆ—åˆ—åœ°ï¼‰æ±‚å‡å€¼
    # å…³äºmeanï¼š[numpy.mean â€” NumPy v1.18 Manual](https://numpy.org/doc/1.18/reference/generated/numpy.mean.html)
    # å…³äºaxis[Numpy axes explained - Sharp Sight](https://www.sharpsightlabs.com/blog/numpy-axes-explained/)
mean = train_data.mean(axis=0)
train_data -= mean
# æ²¿ç€train_dataçš„ç¬¬0å‘¨æ±‚æ ‡å‡†å·®
std = train_data.std(axis=0)
# æ•´ä½“é™¤ä»¥æ ‡å‡†å·®ï¼Œè®­ç»ƒæ•°æ®æ ‡å‡†åŒ–å®Œæˆ
train_data /= std

# åŒç†ï¼Œæ ‡å‡†åŒ–æµ‹è¯•æ•°æ®
## åˆ‡è®°ï¼Œæµ‹è¯•æ•°æ®ä¹Ÿåº”å½“ä½¿ç”¨è®­ç»ƒæ•°æ®æ¥æ ‡å‡†åŒ–
test_data -= mean
test_data /= std



#### 3.6.3 æ„å»ºç½‘ç»œ

### 3-26 æ¨¡å‹å®šä¹‰

from keras import models
from keras import layers

## æ­¤æ¬¡æ ·æœ¬æ•°æ®å°‘ã€‚è®­ç»ƒæ•°æ®è¶Šå°‘ï¼Œè¿‡æ‹Ÿåˆä¼šè¶Šä¸¥é‡ã€‚å› æ­¤æ­å»ºè¾ƒå°çš„ç½‘ç»œã€‚

## å› ä¸ºéœ€è¦å°†åŒä¸€ä¸ªæ¨¡å‹å¤šæ¬¡å®ä¾‹åŒ–ï¼Œæ‰€ä»¥ç”¨ä¸€ä¸ªå‡½æ•°æ¥æ„å»ºæ¨¡å‹ã€‚
def build_model():
    model = models.Sequential()
    model.add(layers.Dense(64, activation='relu',
                           # ä»¥train_dataç¬¬1è½´çš„shapeå³13ä½œä¸ºç¬¬ä¸€å±‚çš„èŠ‚ç‚¹æ•°
                           input_shape=(train_data.shape[1],)))
    model.add(layers.Dense(64, activation='relu'))
    ## çº¿æ€§å±‚ã€‚æ ‡é‡å›å½’çš„å…¸å‹è®¾ç½®ã€‚ä¸ä¼šé™åˆ¶è¾“å‡ºèŒƒå›´ã€‚
    model.add(layers.Dense(1))
    ## mse: å‡æ–¹è¯¯å·®(mean squared error)ï¼Œå³æ ‡å‡†è¯¯çš„å¹³æ–¹
        ## æ ‡å‡†è¯¯çš„æ„ä¹‰ä»€ä¹ˆæ¥ç€ï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼ŸğŸš§è®°å¾—ç¿»å›ç»Ÿè®¡ä¹¦
    ## mae: å¹³å‡ç»å¯¹è¯¯å·®(mean absolute error)ï¼Œ|y^ - y|çš„å‡å€¼
        ## æ¯”å¦‚è¿™æ¬¡å¾—åˆ°MAEç­‰äº0.5ï¼Œè¡¨ç¤ºé¢„æµ‹çš„æˆ¿ä»·ä¸å®é™…æˆ¿ä»·å¹³å‡ç›¸å·® 0.5åƒ ç¾å…ƒ
    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])
    return model



#### 3.6.4 ä½¿ç”¨KæŠ˜éªŒè¯æ¥éªŒè¯ä½ çš„æ–¹æ³•

## ç”±äºæ•°æ®å°‘ï¼ŒéªŒè¯é›†ä¼šå¾ˆå°ã€‚å› æ­¤éªŒè¯åˆ†æ•°å¯èƒ½ä¼šæœ‰å¾ˆå¤§æ³¢åŠ¨ï¼Œå–å†³äºæ‰€é€‰çš„éªŒè¯é›†å’Œè®­ç»ƒé›†ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒéªŒè¯é›†çš„åˆ’åˆ†æ–¹å¼å¯èƒ½ä¼šé€ æˆéªŒè¯åˆ†æ•°æœ‰å¾ˆå¤§çš„æ–¹å·®ã€‚
## KæŠ˜äº¤å‰éªŒè¯å¯å°†æ•°æ®åˆ†ä¸ºKä¸ªåˆ†åŒºï¼ˆKå¸¸å–4æˆ–5ï¼‰ã€‚æ¯æ¬¡åœ¨æ¨¡å‹çš„K-1ä¸ªåˆ†åŒºä¸Šè®­ç»ƒï¼Œå‰©ä½™1ä¸ªåˆ†åŒºç”¨äºæµ‹è¯•ã€‚å…±é‡å¤Kæ¬¡ï¼Œå–Kä¸ªéªŒè¯åˆ†æ•°çš„å¹³å‡å€¼ã€‚

### 3-27 KæŠ˜éªŒè¯

import numpy as np

k = 4
# kåˆ†train_dataçš„é•¿åº¦ï¼Œä¹Ÿå°±æ˜¯æ¯ä¸€æŠ˜çš„æ ·æœ¬æœ‰101ä¸ª
num_val_samples = len(train_data) // k
# ?
num_epochs = 100
all_scores = []

# åœ¨ç¬¬iæŠ˜è®­ç»ƒä¸éªŒè¯ä¸­
for i in range(k):
    print('processing fold #', i)
    # éªŒè¯æ•°æ®ã€‚åˆ‡ç‰‡ä¸‹é™ä¸ºi * num_val_samplesï¼Œåˆ‡ç‰‡ä¸Šé™ä¸º(i + 1) * num_val_samples
    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]
    # éªŒè¯æ ‡ç­¾åŒç†
    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]
    
    # è®­ç»ƒæ•°æ®å’Œè®­ç»ƒæ ‡ç­¾ï¼šä½™ä¸‹å…¨éƒ¨åˆ†åŒºçš„æ•°æ®ï¼ˆå°±æ˜¯ä¸Šé¢éªŒè¯æ•°æ®çš„åŒºé—´çš„è¡¥é›†ï¼‰
        # [numpy.concatenate â€” NumPy v1.18 Manual](https://numpy.org/doc/1.18/reference/generated/numpy.concatenate.html)
            # æ²¿ç€ï¼ˆé»˜è®¤ï¼‰axis=0æ¥æ‹¼æ¥ä¸¤æ®µæ•°ç»„
            # å¯ç†è§£ä¸ºseq.join()çš„æ¨å¹¿
    partial_train_data = np.concatenate(
        [train_data[:i * num_val_samples],
         train_data[(i + 1) * num_val_samples:]],
        axis=0)
    partial_train_targets = np.concatenate(
        [train_targets[:i * num_val_samples],
         train_targets[(i + 1) * num_val_samples:]],
        axis=0)
    
    ## æ„å»ºKerasæ¨¡å‹ï¼ˆå·²ç¼–è¯‘ï¼‰
    model = build_model()
    ## verbose=0: é™é»˜æ¨¡å¼ ï¼ˆå¯æ˜¯æ˜¯ä»€ä¹ˆæ„æ€â“å“¦ï¼Œè®­ç»ƒæˆ–æµ‹è¯•æ—¶ä¸æ˜¾ç¤ºå³æ—¶è¿›åº¦ï¼‰
        # ä½ çœ‹ï¼Œæœ«å°¾åˆ æ‰verbose=0å°±å›å¤å³æ—¶çŠ¶æ€æ˜¾ç¤ºäº†
    model.fit(partial_train_data, partial_train_targets,
              epochs=num_epochs, batch_size=1)
    # https://keras.io/models/model/#evaluate
        # ä¾æ¬¡è¿”å›losså’Œmetrics
    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)
    all_scores.append(val_mae)

print(all_scores)
# æ³¨æ„åŒºåˆ†ï¼šmeanä½œä¸ºå±æ€§å’Œä½œä¸ºæ–¹æ³•ï¼ˆç±»æ¯”s.sort()ä¸sorted(s)çš„åŒºåˆ«ï¼‰
print(np.mean(all_scores))
# åœ¨2~3ä¹‹é—´ï¼Œå³2000~3000ç¾å…ƒï¼Œè¿™ä¸ªé¢„æµ‹å€¼å’Œå®é™…å€¼çš„åå·®è¿˜æ˜¯æŒºå¤§